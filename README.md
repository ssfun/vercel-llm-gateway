# Vercel API Gateway for LLM Services

ä¸€ä¸ªé«˜æ€§èƒ½çš„æ··åˆ API ç½‘å…³ï¼Œä¸“ä¸º AI/LLM æœåŠ¡è®¾è®¡ï¼Œç»“åˆ Vercel Edge Functions å’Œ Serverless Functions çš„ä¼˜åŠ¿ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸš€ åŒè¿è¡Œæ—¶æ¶æ„
- **Edge Functions**: å¤„ç†å¿«é€Ÿå“åº”å’Œæµå¼è¯·æ±‚ï¼ˆSSEï¼‰ï¼Œ20 ç§’è¶…æ—¶é™åˆ¶
- **Serverless Functions**: å¤„ç†é•¿æ—¶é—´ä»»åŠ¡ï¼Œæ”¯æŒæœ€é•¿ 5 åˆ†é’Ÿæ‰§è¡Œ
- **æ™ºèƒ½è·¯ç”±**: è‡ªåŠ¨è¯†åˆ«è¯·æ±‚ç±»å‹å¹¶è·¯ç”±åˆ°æœ€ä¼˜è¿è¡Œæ—¶

### ğŸ”„ æ™ºèƒ½è¯·æ±‚å¤„ç†
- **æµå¼å“åº”æ”¯æŒ**: å®Œç¾æ”¯æŒ SSEï¼ˆServer-Sent Eventsï¼‰å’Œæµå¼ API
- **è‡ªåŠ¨é‡è¯•æœºåˆ¶**: å¸¦æŒ‡æ•°é€€é¿çš„æ™ºèƒ½é‡è¯•
- **é™çº§ç­–ç•¥**: Background å¤±è´¥è‡ªåŠ¨é™çº§åˆ° Edge å¤„ç†
- **å¤§æ–‡ä»¶å¤„ç†**: è‡ªåŠ¨è¯†åˆ«å¤§è¯·æ±‚å¹¶è·¯ç”±åˆ° Background

### ğŸ›¡ï¸ å®‰å…¨ä¸ç›‘æ§
- **è¯·æ±‚å¤´è¿‡æ»¤**: è‡ªåŠ¨è¿‡æ»¤æ•æ„Ÿå’Œä¸å¿…è¦çš„è¯·æ±‚å¤´
- **å“åº”å¤§å°é™åˆ¶**: é˜²æ­¢è¶…å¤§å“åº”å¯¼è‡´çš„é—®é¢˜
- **å®Œæ•´çš„è¯·æ±‚è¿½è¸ª**: æ¯ä¸ªè¯·æ±‚éƒ½æœ‰å”¯ä¸€ ID ä¾¿äºè°ƒè¯•
- **è¯¦ç»†æ—¥å¿—è®°å½•**: åˆ†çº§æ—¥å¿—ç³»ç»Ÿï¼ˆDEBUG/INFO/WARN/ERRORï¼‰

### ğŸŒ æ”¯æŒçš„ AI æœåŠ¡

| æœåŠ¡ | åŸŸå | æµå¼æ”¯æŒ | è¯´æ˜ |
|------|------|---------|------|
| OpenAI | api.openai.com | âœ… | GPT-3.5/4, DALL-E, Whisper |
| Anthropic Claude | api.anthropic.com | âœ… | Claude 3 ç³»åˆ— |
| Google Gemini | generativelanguage.googleapis.com | âœ… | Gemini Pro/Ultra |
| Azure AI | models.inference.ai.azure.com | âœ… | Azure OpenAI Service |
| Groq | api.groq.com | âœ… | è¶…å¿«é€Ÿæ¨ç† |
| Cohere | api.cohere.ai | âœ… | Command, Embed |
| HuggingFace | api-inference.huggingface.co | âš ï¸ | å¼€æºæ¨¡å‹ |
| Together AI | api.together.xyz | âœ… | å¼€æºæ¨¡å‹èšåˆ |
| SiliconFlow | api.siliconflow.cn | âœ… | å›½å†…ä¼˜åŒ– |
| GitHub Models | models.github.ai | âœ… | GitHub AI æ¨¡å‹ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä¸€é”®éƒ¨ç½²åˆ° Vercel

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/ssfun/vercel-llm-gateway)

### 2. æ‰‹åŠ¨éƒ¨ç½²

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/ssfun/vercel-llm-gateway.git
cd vercel-llm-gateway

# å®‰è£…ä¾èµ–
npm install

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶

# æœ¬åœ°å¼€å‘
npm run dev

# éƒ¨ç½²åˆ° Vercel
npm run deploy
```

### 3. ç¯å¢ƒå˜é‡é…ç½®

åœ¨ Vercel Dashboard æˆ– `.env` æ–‡ä»¶ä¸­é…ç½®ï¼š

```env
# åŸºç¡€é…ç½®
ALLOWED_ORIGIN=*                    # CORS å…è®¸çš„æº
DEFAULT_TIMEOUT=20000               # Edge é»˜è®¤è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
BACKGROUND_TIMEOUT=240000           # Background è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
MAX_RESPONSE_SIZE=6291456          # æœ€å¤§å“åº”å¤§å°ï¼ˆå­—èŠ‚ï¼‰
ENABLE_RETRY=true                   # å¯ç”¨é‡è¯•
ENABLE_FALLBACK=true                # å¯ç”¨é™çº§
LOG_LEVEL=INFO                      # æ—¥å¿—çº§åˆ«

# è‡ªå®šä¹‰ä»£ç†é…ç½®ï¼ˆå¯é€‰ï¼‰
PROXY_CONFIG='{"custom":{"host":"api.custom.com"}}'
```

## ğŸ“– ä½¿ç”¨æŒ‡å—

### åŸºç¡€è¯·æ±‚æ ¼å¼

```
https://your-domain.vercel.app/gateway/{service}/{path}
```

### ç¤ºä¾‹è¯·æ±‚

#### OpenAI Chat Completionï¼ˆéæµå¼ï¼‰

```bash
curl -X POST https://your-domain.vercel.app/gateway/openai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-..." \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello!"}
    ]
  }'
```

#### OpenAI Chat Completionï¼ˆæµå¼ï¼‰

```bash
curl -X POST https://your-domain.vercel.app/gateway/openai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-..." \
  -H "Accept: text/event-stream" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Write a story"}],
    "stream": true
  }'
```

#### Claude Messages API

```bash
curl -X POST https://your-domain.vercel.app/gateway/claude/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-api-key: sk-ant-..." \
  -H "anthropic-version: 2023-06-01" \
  -d '{
    "model": "claude-3-opus-20240229",
    "messages": [{"role": "user", "content": "Hello Claude!"}],
    "max_tokens": 1024
  }'
```

#### Google Gemini

```bash
curl -X POST https://your-domain.vercel.app/gateway/gemini/v1beta/models/gemini-pro:generateContent \
  -H "Content-Type: application/json" \
  -H "x-goog-api-key: ..." \
  -d '{
    "contents": [{
      "parts": [{"text": "Explain quantum computing"}]
    }]
  }'
```

#### å¥åº·æ£€æŸ¥

```bash
# ç½‘å…³å¥åº·æ£€æŸ¥
curl https://your-domain.vercel.app/gateway/health

# è¿”å›ç¤ºä¾‹
{
  "status": "ok",
  "timestamp": "2024-01-01T00:00:00.000Z",
  "service": "api-gateway",
  "mode": "edge",
  "version": "1.0.0",
  "env": "production"
}
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### è¯·æ±‚å¤„ç†æµç¨‹

```mermaid
graph TD
    A[å®¢æˆ·ç«¯è¯·æ±‚] --> B[Edge Gateway]
    B --> C{è¯·æ±‚ç±»å‹åˆ¤æ–­}
    
    C -->|æµå¼è¯·æ±‚| D[Edge Function å¤„ç†]
    C -->|å¿«é€Ÿè¯·æ±‚| D
    C -->|é•¿ä»»åŠ¡è¯·æ±‚| E[è½¬å‘åˆ° Background]
    
    D --> F[ç›´æ¥ä»£ç†åˆ°ä¸Šæ¸¸]
    E --> G[Background Function]
    G --> H[æ‰§è¡Œé•¿æ—¶é—´ä»»åŠ¡]
    
    F --> I[è¿”å›å“åº”]
    H --> I
    
    B -.->|å¤±è´¥é™çº§| D
```

### æ™ºèƒ½è·¯ç”±è§„åˆ™

| è¯·æ±‚ç±»å‹ | å¤„ç†æ–¹å¼ | æ¡ä»¶ |
|---------|---------|------|
| GET/HEAD/OPTIONS | Edge | æ‰€æœ‰æƒ…å†µ |
| æµå¼è¯·æ±‚ | Edge | `stream=true` æˆ– SSE |
| å°è¯·æ±‚ä½“ POST | Edge | < 1MB |
| å¤§è¯·æ±‚ä½“ POST | Background | > 1MB |
| éŸ³é¢‘/å›¾åƒç”Ÿæˆ | Background | ç‰¹å®š API è·¯å¾„ |
| Embeddings | Background | `/v1/embeddings` |
| æ–‡ä»¶æ“ä½œ | Background | `/v1/files` |

## ğŸ› ï¸ é«˜çº§é…ç½®

### æ·»åŠ è‡ªå®šä¹‰æœåŠ¡

åœ¨ç¯å¢ƒå˜é‡ `PROXY_CONFIG` ä¸­æ·»åŠ ï¼š

```json
{
  "myservice": {
    "host": "api.myservice.com",
    "basePath": "v1",
    "timeout": 30000,
    "maxRetries": 3,
    "retryableMethods": ["GET", "POST"],
    "defaultHeaders": {
      "X-Custom-Header": "value"
    },
    "supportsStreaming": true,
    "allowFallback": true
  }
}
```

### è‡ªå®šä¹‰é‡è¯•ç­–ç•¥

ä¿®æ”¹ `api/_shared/middleware.ts`:

```typescript
// è‡ªå®šä¹‰é‡è¯•æ¡ä»¶
const retryableErrors = ['timeout', 'network', 'connection'];

// è‡ªå®šä¹‰é€€é¿ç­–ç•¥
const baseDelay = Math.min(100 * Math.pow(2, attempt), 5000);
const jitter = baseDelay * 0.3 * (Math.random() - 0.5);
```

### è°ƒæ•´è¶…æ—¶è®¾ç½®

```env
# Edge Function è¶…æ—¶ï¼ˆæœ€å¤§ 20 ç§’ï¼‰
DEFAULT_TIMEOUT=15000

# Background Function è¶…æ—¶ï¼ˆæœ€å¤§ 300 ç§’ï¼‰
BACKGROUND_TIMEOUT=300000
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### Edge Function ä¼˜åŒ–
- **è¶…æ—¶è®¾ç½®**: 20 ç§’ï¼ˆé¿å…è§¦å‘ 25 ç§’ç¡¬é™åˆ¶ï¼‰
- **æµå¼å“åº”**: ç«‹å³è¿”å›å“åº”å¤´ï¼Œé¿å…è¶…æ—¶
- **è¯·æ±‚å…‹éš†**: é¿å…é‡å¤è¯»å–è¯·æ±‚ä½“

### Background Function ä¼˜åŒ–
- **é•¿ä»»åŠ¡æ”¯æŒ**: æœ€é•¿ 5 åˆ†é’Ÿæ‰§è¡Œæ—¶é—´
- **å†…å­˜é…ç½®**: 1024MB å†…å­˜åˆ†é…
- **å¹¶å‘å¤„ç†**: è‡ªåŠ¨æ‰©å±•å¤„ç†å¹¶å‘è¯·æ±‚

### ç½‘ç»œä¼˜åŒ–
- **æ™ºèƒ½é‡è¯•**: æŒ‡æ•°é€€é¿ + æŠ–åŠ¨
- **è¿æ¥å¤ç”¨**: Keep-Alive è¿æ¥
- **å“åº”å‹ç¼©**: è‡ªåŠ¨ gzip å‹ç¼©

## ğŸ” ç›‘æ§ä¸è°ƒè¯•

### è¯·æ±‚è¿½è¸ª

æ¯ä¸ªè¯·æ±‚éƒ½æœ‰å”¯ä¸€çš„ Request IDï¼š

```bash
# å“åº”å¤´ä¸­åŒ…å«
X-Request-Id: uuid-xxxx-xxxx
X-Processing-Mode: edge|background
X-Processing-Time: 1234
```

### æ—¥å¿—æŸ¥çœ‹

åœ¨ Vercel Dashboard çš„ Functions æ ‡ç­¾é¡µæŸ¥çœ‹å®æ—¶æ—¥å¿—ï¼š

```
[2024-01-01 12:00:00.000] [req-id] [INFO] Gateway æ”¶åˆ°è¯·æ±‚ | method=POST path=/gateway/openai/v1/chat/completions
[2024-01-01 12:00:00.100] [req-id] [DEBUG] è·¯ç”±å†³ç­– | decision=edge reason=Streaming request
[2024-01-01 12:00:01.000] [req-id] [INFO] Edge è¯·æ±‚å®Œæˆ | status=200 duration_ms=1000
```

### é”™è¯¯å¤„ç†

ç»Ÿä¸€çš„é”™è¯¯å“åº”æ ¼å¼ï¼š

```json
{
  "error": {
    "message": "é”™è¯¯æè¿°",
    "type": "TIMEOUT|NETWORK|DNS|CONNECTION|SSL|SIZE_LIMIT|UNKNOWN",
    "request_id": "uuid-xxxx",
    "timestamp": "2024-01-01T00:00:00.000Z"
  },
  "status": 500
}
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. Edge Function è¶…æ—¶
- **é—®é¢˜**: è¯·æ±‚åœ¨ 25 ç§’åè¶…æ—¶
- **è§£å†³**: ç¡®ä¿é•¿ä»»åŠ¡è¢«æ­£ç¡®è·¯ç”±åˆ° Background Function

#### 2. CORS é”™è¯¯
- **é—®é¢˜**: æµè§ˆå™¨æŠ¥å‘Š CORS é”™è¯¯
- **è§£å†³**: æ£€æŸ¥ `ALLOWED_ORIGIN` ç¯å¢ƒå˜é‡è®¾ç½®

#### 3. 413 é”™è¯¯
- **é—®é¢˜**: å“åº”å¤§å°è¶…è¿‡é™åˆ¶
- **è§£å†³**: è°ƒæ•´ `MAX_RESPONSE_SIZE` ç¯å¢ƒå˜é‡

#### 4. é‡è¯•è¿‡å¤š
- **é—®é¢˜**: è¯·æ±‚é‡è¯•æ¬¡æ•°è¿‡å¤šå¯¼è‡´å»¶è¿Ÿ
- **è§£å†³**: è°ƒæ•´ `maxRetries` é…ç½®æˆ–ç¦ç”¨é‡è¯•

## ğŸ“ å¼€å‘æŒ‡å—

### æœ¬åœ°å¼€å‘

```bash
# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev

# ç±»å‹æ£€æŸ¥
npm run lint

# æ ¼å¼åŒ–ä»£ç 
npm run format
```

### é¡¹ç›®ç»“æ„

```
vercel-llm-gateway/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ _shared/           # å…±äº«æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ config.ts      # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ types.ts       # ç±»å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ logger.ts      # æ—¥å¿—ç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ utils.ts       # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ errors.ts      # é”™è¯¯å¤„ç†
â”‚   â”‚   â””â”€â”€ middleware.ts  # ä¸­é—´ä»¶
â”‚   â”œâ”€â”€ gateway.ts         # Edge Gateway ä¸»å…¥å£
â”‚   â””â”€â”€ background.ts      # Background Function
â”œâ”€â”€ public/
â”‚   â””â”€â”€ index.html         # æ¬¢è¿é¡µé¢
â”œâ”€â”€ package.json
â”œâ”€â”€ vercel.json           # Vercel é…ç½®
â”œâ”€â”€ tsconfig.json         # TypeScript é…ç½®
â””â”€â”€ README.md
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

### è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æäº¤ Pull Request

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ“® è”ç³»

- GitHub: [@ssfun](https://github.com/ssfun)
- Issues: [GitHub Issues](https://github.com/ssfun/vercel-llm-gateway/issues)

---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Starï¼**
